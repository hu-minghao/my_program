{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型融合\n",
    "\n",
    "最后一章，做模型融合，这应该是所有比赛最后都需要经历的一环，因为模型融合确实可以提高一点比赛分数，如视频直播中所说，可以榨干模型的最后一点能力。对有的任务，模型融合提升还是蛮大的，如回归类问题。而分类问题，模型融合带来的提升貌似比较小，最高可以带来2%左右的提高。\n",
    "\n",
    "### 交叉验证训练多模型\n",
    "深度学习训练一般需要耗费很长时间，如果算力限制，可以考虑留出法训练多个模型，这次模型融合，以交叉验证训练十个模型，然后取均值，或者投票法，可以达到模型融合的效果。\n",
    "\n",
    "### 测试数据扩展TTA\n",
    "第二种是，在测试时做测试数据扩展，即在测试时对测试数据进行轻微调整，然后进行多次预测，最后投票。\n",
    "\n",
    "### 一个训练模型的多个局部最优点模型融合\n",
    "其实单个模型也可以做模型融合，这里介绍了一种叫Snapshot Ensembles的方法。即在周期性变大变小的学习率中，checkpoint，取得许多局部最优点，然后对着一系列checkpoint点取模型参数，也可以获得融合的模型。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在交叉验证时，常常加入Dropout，以增强模型随机性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import os, sys, glob, shutil, json\n",
    "import cv2\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import torch\n",
    "#torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = False\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义自己的数据集类,从Dataset处继承\n",
    "class MyDataset(Dataset):\n",
    "    #定义初始化方法\n",
    "    def __init__(self,img_path,img_label,transform=None):\n",
    "        #三个参数，图片路径，图片标签和转化方式，转化方式与数据集扩展有关\n",
    "        self.img_path=img_path\n",
    "        self.img_label=img_label\n",
    "        #注意我们可以先不进行数据增强，所以要加判断\n",
    "        if transform !=None:\n",
    "            self.transform=transform\n",
    "        else:\n",
    "            self.transform=None\n",
    "    \n",
    "    #构建数据集需要两个方法，一个是getitem,一个是len,这里我觉得getitem就是调用这个datasset后，会一个一个返回数据和标签的方法\n",
    "    #len会返回数据集大小，这个getitem是按编号返回数据及标签。\n",
    "    \n",
    "    #这里的open是打开一个文件夹，注意，这里文件是一个一个读取的，img_path是一个list!所以有索引！！！，同理，label——path\n",
    "    #也是一样.\n",
    "    def __getitem__(self, index):\n",
    "        #读取图片的方法可以换\n",
    "        img = Image.open(self.img_path[index]).convert('RGB')\n",
    "    #转换img\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        # 设置最长的字符长度为5个,读取label,注意这里转换了一下数据类型\n",
    "        lbl = np.array(self.img_label[index], dtype=np.int)\n",
    "        #由于是固定长度，所以将不足5位的地方补足了\n",
    "        lbl = list(lbl)  + (5 - len(lbl)) * [10]\n",
    "        return img, torch.from_numpy(np.array(lbl[:5]))\n",
    "   #这里再次注意img_path是一个列表\n",
    "    def __len__(self):\n",
    "        return len(self.img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000 30000\n"
     ]
    }
   ],
   "source": [
    "#glob.glob读取结果是一个列表，类似于linnix的查找文件方式，可迭代对象\n",
    "train_path = glob.glob('E:/Machine Learning/CV字符/mchar_train/mchar_train/*.png')\n",
    "#列表排序\n",
    "train_path.sort()\n",
    "#json.load()是用来读取文件的，即，将文件打开然后就可以直接读取。示例如下\n",
    "#with open(\"文件名\") as f:\n",
    "#    result=json.load(f)\n",
    "train_json = json.load(open('E:/Machine Learning/CV字符/mchar_train.json'))\n",
    "#json文件格式类似于字典，下面是一个试例\n",
    "#{\"000000.png\": {\"height\": [219, 219], \"label\": [1, 9], \"left\": [246, 323], \"top\": [77, 81], \"width\": [81, 96]},\n",
    "train_label = [train_json[x]['label'] for x in train_json]\n",
    "print(len(train_path), len(train_label))\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    MyDataset(train_path, train_label,\n",
    "                transforms.Compose([\n",
    "                    transforms.Resize((64, 128)),\n",
    "                    transforms.RandomCrop((60, 120)),\n",
    "                    transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=40, \n",
    "    shuffle=True, \n",
    "    num_workers=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 10000\n"
     ]
    }
   ],
   "source": [
    "val_path = glob.glob('E:/Machine Learning/CV字符/mchar_val/mchar_val/*.png')\n",
    "val_path.sort()\n",
    "val_json = json.load(open('E:/Machine Learning/CV字符/mchar_val.json'))\n",
    "val_label = [val_json[x]['label'] for x in val_json]\n",
    "print(len(val_path), len(val_label))\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    MyDataset(val_path, val_label,\n",
    "                transforms.Compose([\n",
    "                    #transforms.Resize((60, 120)),\n",
    "                    # transforms.ColorJitter(0.3, 0.3, 0.2),\n",
    "                    # transforms.RandomRotation(5),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])), \n",
    "    batch_size=40, \n",
    "    shuffle=False, \n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHN_Model1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SVHN_Model1, self).__init__()\n",
    "        # CNN提取特征模块\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.25),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2)),\n",
    "            nn.ReLU(), \n",
    "            nn.Dropout(0.25),\n",
    "            nn.MaxPool2d(2),\n",
    "        )\n",
    "        # \n",
    "        self.fc1 = nn.Linear(32*3*7, 11)\n",
    "        self.fc2 = nn.Linear(32*3*7, 11)\n",
    "        self.fc3 = nn.Linear(32*3*7, 11)\n",
    "        self.fc4 = nn.Linear(32*3*7, 11)\n",
    "        self.fc5 = nn.Linear(32*3*7, 11)\n",
    "        self.fc6 = nn.Linear(32*3*7, 11)\n",
    "    \n",
    "    def forward(self, img):\n",
    "        feat = self.cnn(img)\n",
    "        feat = feat.view(feat.shape[0], -1)\n",
    "        c1 = self.fc1(feat)\n",
    "        c2 = self.fc2(feat)\n",
    "        c3 = self.fc3(feat)\n",
    "        c4 = self.fc4(feat)\n",
    "        c5 = self.fc5(feat)\n",
    "        c6 = self.fc6(feat)\n",
    "        return c1, c2, c3, c4, c5, c6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTA代码\n",
    "测试集数据扩增（Test Time Augmentation，简称TTA）也是常用的集成学习技巧，数据扩增不仅可以在训练时候用，而且可以同样在预测时候进行数据扩增，对同一个样本预测三次，然后对三次结果进行平均。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def predict(test_loader, model, tta=10):\n",
    "    model.eval()\n",
    "    test_pred_tta = None\n",
    "    # TTA 次数\n",
    "    for _ in range(tta):\n",
    "        test_pred = []\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            for i, (input, target) in enumerate(test_loader):\n",
    "                c0, c1, c2, c3, c4, c5 = model(data[0])\n",
    "                output = np.concatenate([c0.data.numpy(), c1.data.numpy(),\n",
    "                   c2.data.numpy(), c3.data.numpy(),\n",
    "                   c4.data.numpy(), c5.data.numpy()], axis=1)\n",
    "                test_pred.append(output)\n",
    "        \n",
    "        test_pred = np.vstack(test_pred)\n",
    "        if test_pred_tta is None:\n",
    "            test_pred_tta = test_pred\n",
    "        else:\n",
    "            test_pred_tta += test_pred\n",
    "    \n",
    "    return test_pred_tta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "\n",
    "- 集成学习只能在一定程度上提高精度，并需要耗费较大的训练时间，因此建议先使用提高单个模型的精度，再考虑集成学习过程；\n",
    "- 具体的集成学习方法需要与验证集划分方法结合，Dropout和TTA在所有场景有可以起作用"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
