{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('D:/Documents/Downloads/used_car_train.csv')\n",
    "test=pd.read_csv('D:/Documents/Downloads/used_car_test.csv')\n",
    "target=pd.read_csv('D:/Documents/Downloads/target.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def NN_model(input_dim):\n",
    "    reg=Sequential()\n",
    "    reg.add(Dense(units=200,input_shape=(input_dim,),kernel_initializer='glorot_uniform',\n",
    "                  kernel_regularizer=regularizers.l1(0.01),activation='softplus'))\n",
    "    reg.add(Dense(units=64,kernel_initializer='glorot_uniform',activation='softplus'))\n",
    "    reg.add(Dense(units=32,kernel_initializer='glorot_uniform',activation='softplus'))\n",
    "    reg.add(Dense(units=8, kernel_initializer='glorot_uniform',activation='softplus'))\n",
    "    reg.add(Dense(units=1))\n",
    "    return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 200)               18400     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 64)                12864     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 8)                 264       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 33,617\n",
      "Trainable params: 33,617\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=NN_model(train.shape[1])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1\n",
      "120000/120000 [==============================] - 4s 30us/step - loss: 6370.1874 - mae: 6206.1743 - val_loss: 6097.6614 - val_mae: 5891.1426\n"
     ]
    }
   ],
   "source": [
    "epoch=1\n",
    "b_size=1500\n",
    "opt=optimizers.SGD(learning_rate=0.01,decay=0.01/epoch,momentum=0.9,nesterov=True)\n",
    "model.compile(loss='mae',optimizer=opt,metrics=['mae'])\n",
    "history=model.fit(x=train,y=target,validation_split=0.2,batch_size=b_size, epochs=epoch,shuffle = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold: 0\n",
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 2034.6034 - mae: 1983.1505 - val_loss: 1111.5808 - val_mae: 1054.2446\n",
      "fold: 1\n",
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 1942.7608 - mae: 1900.8298 - val_loss: 1160.0779 - val_mae: 1115.8635\n",
      "fold: 2\n",
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 1593.3762 - mae: 1548.8121 - val_loss: 1169.6701 - val_mae: 1123.1195\n",
      "fold: 3\n",
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1\n",
      " - 3s - loss: 1534.2492 - mae: 1491.8263 - val_loss: 1061.8437 - val_mae: 1017.3713\n",
      "fold: 4\n",
      "Train on 120000 samples, validate on 30000 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 1606.1932 - mae: 1557.9359 - val_loss: 1161.3056 - val_mae: 1109.9398\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping,callbacks\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import math \n",
    "\n",
    "def step_decay(epoch):\n",
    "    initial_lrate = 0.1\n",
    "    drop = 0.2\n",
    "    epochs_drop = 5.0\n",
    "    lrate = initial_lrate * math.pow(drop,math.floor((1+epoch)/epochs_drop))\n",
    "    return lrate\n",
    "lrate = LearningRateScheduler(step_decay)\n",
    "\n",
    "n_split=5\n",
    "K=KFold(n_splits=n_split)\n",
    "\n",
    "b_size=1500\n",
    "max_epochs=1\n",
    "x=train.values\n",
    "y=target.values\n",
    "for fold,(tra_idx,val_idx) in enumerate(K.split(x,y)):\n",
    "    print('fold:',fold)\n",
    "    X_train,y_train=x[tra_idx],y[tra_idx]\n",
    "    X_val,y_val=x[val_idx],y[val_idx]\n",
    "    model=NN_model(91)\n",
    "    opt=optimizers.Adam(lr=0.015)\n",
    "    model.compile(optimizer=opt,loss='mae',metrics=['mae'])\n",
    "    es = EarlyStopping(monitor='val_score', patience=5, \n",
    "                       verbose=2, mode='min',restore_best_weights=True)\n",
    "    es.set_model(model)\n",
    "    model.fit(X_train, y_train, batch_size=b_size, epochs=max_epochs, \n",
    "              validation_data = [X_val, y_val],\n",
    "              callbacks=[lrate], shuffle=True, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
